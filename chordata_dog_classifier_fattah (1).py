# -*- coding: utf-8 -*-
"""CHORDATA DOG CLASSIFIER - FATTAH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16frnsENheE75S-_qAx4wrvI-84Ta3q43
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import scipy.stats as st
from sklearn import ensemble, tree, linear_model
import missingno as msno
import numpy as np
from sklearn.model_selection import train_test_split
from scipy import stats
from scipy.signal import find_peaks
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
warnings.filterwarnings('ignore')
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

#importing data & dataframe variable definition, in order to save processing power and increase speed of work flow I analyze the data for DOG 16 and also convert all the data from float 64 to float 32

dog_df = pd.read_csv(r"/content/drive/MyDrive/DOG16DATA")
df = dog_df.astype({'DogID': 'int32','TestNum': 'int32',
                'ABack_x' : 'float32',
                'ABack_y' : 'float32',
                'ABack_z' : 'float32',
                'ANeck_x' : 'float32',
                'ANeck_y' : 'float32',
                'ANeck_z' : 'float32',
                'GBack_x' : 'float32',
                'GBack_y' : 'float32',
                'GBack_z' : 'float32',
                'GNeck_x' : 'float32',
                'GNeck_y' : 'float32',
                'GNeck_z' : 'float32'})


#dropping features that perhaps aren't statistically important
new_df=df.drop(['PointEvent', 'Task', 'Behavior_2', 'Behavior_3'], axis=1)

new_df.head(10)

#checking for missing data in dataframe

msno.matrix(new_df.sample(250))

#looking at unique values of column 'Behavior_1'


new_df['Behavior_1'].unique()

#Mapping the values other than sitting or lying chest to "moving"


new_df[['Behavior_1']] = new_df[['Behavior_1']].replace(dict.fromkeys(['<undefined>', 'Synchronization', 'Walking', 'Shaking', 'Sniffing',
       'Eating', 'Trotting', 'Pacing','Playing', 'Standing', 'Panting', 'Drinking', 'Galloping',
       'Carrying object', 'Extra_Synchronization', 'Tugging', 'Jumping',
       'Bowing'], 'Moving'))

new_df.head(10)

#same process for 'Behavior_2 & 3'

new_df['Behavior_2'].describe()



new_df[['Behavior_2']] = new_df[['Behavior_2']].replace(dict.fromkeys(['<undefined>', 'Eating', 'Walking', 'Jumping', 'Tugging',
       'Galloping', 'Carrying object', 'Standing', 'Panting','Playing', 'Bowing', 'Trotting',
       'Shaking', 'Pacing'], 'Moving'))

new_df[['Behavior_3']] = new_df[['Behavior_3']].replace(dict.fromkeys(['<undefined>', 'Trotting', 'Galloping', 'Tugging',
       'Carrying object', 'Jumping', 'Standing', 'Pacing',
       'Walking', 'Eating', 'Playing', 'Shaking'], 'Moving'))

new_df.head(20)

# Skewness and Kurtosis


new_df.skew(), new_df.kurt()

y = new_df['ANeck_z']
plt.figure(2); plt.title('Normal')
sns.distplot(y, kde=False, fit=st.norm)

#looking at correlation 

dog_Num = new_df.select_dtypes(include=[np.number])
dog_Num.columns


correlation = dog_Num.corr()
print(correlation['ABack_x'].sort_values(ascending = False),'\n')

f , ax = plt.subplots(figsize = (14,12))

plt.title('Correlation of Numeric Features with Aback_x',y=1,size=16)

sns.heatmap(correlation,square = True,  vmax=0.8)

#scatter plot
Gbackx_scatter_plot = pd.concat([new_df['ABack_y'],new_df['GBack_x']],axis = 1)
sns.regplot(x='ABack_y',y = 'GBack_x',data =Gbackx_scatter_plot,scatter= True, fit_reg=True)

Gbackx_scatter_plot = pd.concat([new_df['ABack_x'], new_df['GNeck_y']],axis = 1)
sns.regplot(x='ABack_x',y = 'GNeck_y',data =Gbackx_scatter_plot,scatter= True, fit_reg=True)

Gbackx_scatter_plot = pd.concat([new_df['ABack_x'], new_df['GNeck_z']],axis = 1)
sns.regplot(x='ABack_x',y = 'GNeck_z',data =Gbackx_scatter_plot,scatter= True, fit_reg=True)

#number of samples by Behavior_1

sns.set_style("darkgrid", {"axes.facecolor": ".9"})
plt.figure(figsize = (10, 5))
sns.countplot(x = ('Behavior_1'), data = new_df)
plt.title("Number of samples by Behavior_1")
plt.show()

#number of samples by Behavior_2

sns.set_style("darkgrid", {"axes.facecolor": ".9"})
plt.figure(figsize = (10, 5))
sns.countplot(x = ('Behavior_2'), data = new_df)
plt.title("Number of samples by Behavior_2")
plt.show()

#Behavior count by Dog ID for Behavior _1

plt.figure(figsize = (18, 6))
sns.countplot(x = 'DogID', hue = 'Behavior_1', data = new_df)
plt.title('Behavior count by Dog ID')
plt.show()

#time series plot of Accelerometers on the dogs back vs time by behavior maps


for i in ['Moving', 'Sitting', 'Lying chest']:
  data_36 = new_df[(new_df['DogID'] == 16) & (new_df['Behavior_1'] == i)][:400]
  plt.figure(figsize = (15, 6))
  sns.lineplot(y = 'ABack_x', x = 't_sec', data = data_36)
  sns.lineplot(y = 'ABack_y', x = 't_sec', data = data_36)
  sns.lineplot(y = 'ABack_z', x = 't_sec', data = data_36)
  plt.legend(['Ax-axis', 'Ay-axis', 'Az-axis'])
  plt.ylabel(i)
  plt.title(i, fontsize = 15)
  plt.show()

#time series plot of Accelerometers on the dogs back vs time by behavior maps


for i in ['Moving', 'Sitting', 'Lying chest']:
  data_36 = new_df[(new_df['DogID'] == 16) & (new_df['Behavior_1'] == i)][:400]
  plt.figure(figsize = (15, 6))
  sns.lineplot(y = 'GBack_x', x = 't_sec', data = data_36)
  sns.lineplot(y = 'GBack_y', x = 't_sec', data = data_36)
  sns.lineplot(y = 'GBack_z', x = 't_sec', data = data_36)
  plt.legend(['x-axis', 'y-axis', 'z-axis'])
  plt.ylabel(i)
  plt.title(i, fontsize = 15)
  plt.show()

#df_train = new_df[new_df['DogID'] <= 60]

#df_test = new_df[new_df['DogID'] > 60]
#df1 = df.iloc[:6]
#df2 = df.iloc[6:]
df_train = new_df.iloc[:200000]
df_test = new_df.iloc[200000:]

df_test.shape

Ax_list = []
Ay_list = []
Az_list = []
Gx_list = []
Gy_list = []
Gz_list = []
train_labels = []

window_size = 100
step_size = 50

# creating overlaping windows of size window-size 100
for i in range(0, df_train.shape[0] - window_size, step_size):
    Ax = df_train['ABack_x'].values[i: i + 100]
    Ay = df_train['ABack_y'].values[i: i + 100]
    Az = df_train['ABack_z'].values[i: i + 100]
    Gx = df_train['GNeck_x'].values[i: i + 100]
    Gy = df_train['GNeck_y'].values[i: i + 100]
    Gz = df_train['GNeck_z'].values[i: i + 100]
    label = stats.mode(df_train['Behavior_1'][i: i + 100])[0][0]

    Ax_list.append(Ax)
    Ay_list.append(Ay)
    Az_list.append(Az)
    Gx_list.append(Gx)
    Gy_list.append(Gy)
    Gz_list.append(Gz)

    train_labels.append(label)

# Statistical Features on raw x, y and z in time domain
X_train = pd.DataFrame()

# mean
X_train['Ax_mean'] = pd.Series(Ax_list).apply(lambda x: x.mean())
X_train['Ay_mean'] = pd.Series(Ay_list).apply(lambda x: x.mean())
X_train['Az_mean'] = pd.Series(Az_list).apply(lambda x: x.mean())
X_train['Gx_mean'] = pd.Series(Gx_list).apply(lambda x: x.mean())
X_train['Gy_mean'] = pd.Series(Gy_list).apply(lambda x: x.mean())
X_train['Gz_mean'] = pd.Series(Gz_list).apply(lambda x: x.mean())

# std dev
X_train['Ax_std'] = pd.Series(Ax_list).apply(lambda x: x.std())
X_train['Ay_std'] = pd.Series(Ay_list).apply(lambda x: x.std())
X_train['Az_std'] = pd.Series(Az_list).apply(lambda x: x.std())
X_train['Gx_std'] = pd.Series(Gx_list).apply(lambda x: x.std())
X_train['Gy_std'] = pd.Series(Gy_list).apply(lambda x: x.std())
X_train['Gz_std'] = pd.Series(Gz_list).apply(lambda x: x.std())
# avg absolute diff
X_train['Ax_aad'] = pd.Series(Ax_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Ay_aad'] = pd.Series(Ay_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Az_aad'] = pd.Series(Az_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gx_aad'] = pd.Series(Gx_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gy_aad'] = pd.Series(Gy_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gz_aad'] = pd.Series(Gz_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))

# min
X_train['Ax_min'] = pd.Series(Ax_list).apply(lambda x: x.min())
X_train['Ay_min'] = pd.Series(Ay_list).apply(lambda x: x.min())
X_train['Az_min'] = pd.Series(Az_list).apply(lambda x: x.min())
X_train['Gx_min'] = pd.Series(Gx_list).apply(lambda x: x.min())
X_train['Gy_min'] = pd.Series(Gy_list).apply(lambda x: x.min())
X_train['Gz_min'] = pd.Series(Gz_list).apply(lambda x: x.min())

# max
X_train['Ax_max'] = pd.Series(Ax_list).apply(lambda x: x.max())
X_train['Ay_max'] = pd.Series(Ay_list).apply(lambda x: x.max())
X_train['Az_max'] = pd.Series(Az_list).apply(lambda x: x.max())
X_train['Gx_max'] = pd.Series(Gx_list).apply(lambda x: x.max())
X_train['Gy_max'] = pd.Series(Gy_list).apply(lambda x: x.max())
X_train['Gz_max'] = pd.Series(Gz_list).apply(lambda x: x.max())

# max-min diff
X_train['Ax_maxmin_diff'] = X_train['Ax_max'] - X_train['Ax_min']
X_train['Ay_maxmin_diff'] = X_train['Ay_max'] - X_train['Ay_min']
X_train['Az_maxmin_diff'] = X_train['Az_max'] - X_train['Az_min']
X_train['Gx_maxmin_diff'] = X_train['Gx_max'] - X_train['Gx_min']
X_train['Gy_maxmin_diff'] = X_train['Gy_max'] - X_train['Gy_min']
X_train['Gz_maxmin_diff'] = X_train['Gz_max'] - X_train['Gz_min']

# median
X_train['Ax_median'] = pd.Series(Ax_list).apply(lambda x: np.median(x))
X_train['Ay_median'] = pd.Series(Ay_list).apply(lambda x: np.median(x))
X_train['Az_median'] = pd.Series(Az_list).apply(lambda x: np.median(x))
X_train['Gx_median'] = pd.Series(Gx_list).apply(lambda x: np.median(x))
X_train['Gy_median'] = pd.Series(Gy_list).apply(lambda x: np.median(x))
X_train['Gz_median'] = pd.Series(Gz_list).apply(lambda x: np.median(x))

# median abs dev 
X_train['Ax_mad'] = pd.Series(Ax_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Ay_mad'] = pd.Series(Ay_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Az_mad'] = pd.Series(Az_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gx_mad'] = pd.Series(Gx_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gy_mad'] = pd.Series(Gy_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gz_mad'] = pd.Series(Gz_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))

# interquartile range
X_train['Ax_IQR'] = pd.Series(Ax_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Ay_IQR'] = pd.Series(Ay_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Az_IQR'] = pd.Series(Az_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gx_IQR'] = pd.Series(Gx_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gy_IQR'] = pd.Series(Gy_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gz_IQR'] = pd.Series(Gz_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))

# negtive count
X_train['Ax_neg_count'] = pd.Series(Ax_list).apply(lambda x: np.sum(x < 0))
X_train['Ay_neg_count'] = pd.Series(Ay_list).apply(lambda x: np.sum(x < 0))
X_train['Az_neg_count'] = pd.Series(Az_list).apply(lambda x: np.sum(x < 0))
X_train['Gx_neg_count'] = pd.Series(Gx_list).apply(lambda x: np.sum(x < 0))
X_train['Gy_neg_count'] = pd.Series(Gy_list).apply(lambda x: np.sum(x < 0))
X_train['Gz_neg_count'] = pd.Series(Gz_list).apply(lambda x: np.sum(x < 0))

# positive count
X_train['Ax_pos_count'] = pd.Series(Ax_list).apply(lambda x: np.sum(x > 0))
X_train['Ay_pos_count'] = pd.Series(Ay_list).apply(lambda x: np.sum(x > 0))
X_train['Az_pos_count'] = pd.Series(Az_list).apply(lambda x: np.sum(x > 0))
X_train['Gx_pos_count'] = pd.Series(Gx_list).apply(lambda x: np.sum(x > 0))
X_train['Gy_pos_count'] = pd.Series(Gy_list).apply(lambda x: np.sum(x > 0))
X_train['Gz_pos_count'] = pd.Series(Gz_list).apply(lambda x: np.sum(x > 0))

# values above mean
X_train['Ax_above_mean'] = pd.Series(Ax_list).apply(lambda x: np.sum(x > x.mean()))
X_train['Ay_above_mean'] = pd.Series(Ay_list).apply(lambda x: np.sum(x > x.mean()))
X_train['Az_above_mean'] = pd.Series(Az_list).apply(lambda x: np.sum(x > x.mean()))
X_train['Gx_above_mean'] = pd.Series(Gx_list).apply(lambda x: np.sum(x > x.mean()))
X_train['Gy_above_mean'] = pd.Series(Gy_list).apply(lambda x: np.sum(x > x.mean()))
X_train['Gz_above_mean'] = pd.Series(Gz_list).apply(lambda x: np.sum(x > x.mean()))

# number of peaks
X_train['Ax_peak_count'] = pd.Series(Ax_list).apply(lambda x: len(find_peaks(x)[0]))
X_train['Ay_peak_count'] = pd.Series(Ay_list).apply(lambda x: len(find_peaks(x)[0]))
X_train['Az_peak_count'] = pd.Series(Az_list).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gx_peak_count'] = pd.Series(Gx_list).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gy_peak_count'] = pd.Series(Gy_list).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gz_peak_count'] = pd.Series(Gz_list).apply(lambda x: len(find_peaks(x)[0]))

# skewness
X_train['Ax_skewness'] = pd.Series(Ax_list).apply(lambda x: stats.skew(x))
X_train['Ay_skewness'] = pd.Series(Ay_list).apply(lambda x: stats.skew(x))
X_train['Az_skewness'] = pd.Series(Az_list).apply(lambda x: stats.skew(x))
X_train['Gx_skewness'] = pd.Series(Gx_list).apply(lambda x: stats.skew(x))
X_train['Gy_skewness'] = pd.Series(Gy_list).apply(lambda x: stats.skew(x))
X_train['Gz_skewness'] = pd.Series(Gz_list).apply(lambda x: stats.skew(x))

# kurtosis
X_train['Ax_kurtosis'] = pd.Series(Ax_list).apply(lambda x: stats.kurtosis(x))
X_train['Ay_kurtosis'] = pd.Series(Ay_list).apply(lambda x: stats.kurtosis(x))
X_train['Az_kurtosis'] = pd.Series(Az_list).apply(lambda x: stats.kurtosis(x))
X_train['Gx_kurtosis'] = pd.Series(Gx_list).apply(lambda x: stats.kurtosis(x))
X_train['Gy_kurtosis'] = pd.Series(Gy_list).apply(lambda x: stats.kurtosis(x))
X_train['Gz_kurtosis'] = pd.Series(Gz_list).apply(lambda x: stats.kurtosis(x))

# energy
X_train['Ax_energy'] = pd.Series(Ax_list).apply(lambda x: np.sum(x**2)/100)
X_train['Ay_energy'] = pd.Series(Ay_list).apply(lambda x: np.sum(x**2)/100)
X_train['Az_energy'] = pd.Series(Az_list).apply(lambda x: np.sum(x**2/100))
X_train['Gx_energy'] = pd.Series(Gx_list).apply(lambda x: np.sum(x**2)/100)
X_train['Gy_energy'] = pd.Series(Gy_list).apply(lambda x: np.sum(x**2)/100)
X_train['Gz_energy'] = pd.Series(Gz_list).apply(lambda x: np.sum(x**2/100))


# avg resultant
X_train['avg_result_accl'] = [i.mean() for i in ((pd.Series(Ax_list)**2 + pd.Series(Ay_list)**2 + pd.Series(Az_list)**2 + pd.Series(Gx_list)**2 + pd.Series(Gy_list)**2 + pd.Series(Gz_list)**2)**0.5)]

# signal magnitude area
#X_train['sma'] =    pd.Series(Ax_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(Ay_list).apply(lambda x: np.sum(abs(x)/100)) 
                  #+ pd.Series(Az_list).apply(lambda x: np.sum(abs(x)/100) +  pd.Series(Gx_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(Gy_list).apply(lambda x: np.sum(abs(x)/100)) 
                  #+ pd.Series(Gz_list).apply(lambda x: np.sum(abs(x)/100))

pd.Series(np.fft.fft(pd.Series(Gx_list)[42])).plot()
plt.show()

# converting the signals from time domain to frequency domain using FFT
Ax_list_fft = pd.Series(Ax_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Ay_list_fft = pd.Series(Ay_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Az_list_fft = pd.Series(Az_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gx_list_fft = pd.Series(Gx_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gy_list_fft = pd.Series(Gy_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gz_list_fft = pd.Series(Gz_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])


# Statistical Features on raw x, y and z in frequency domain
# FFT mean
X_train['Ax_mean_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.mean())
X_train['Ay_mean_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.mean())
X_train['Az_mean_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.mean())
X_train['Gx_mean_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.mean())
X_train['Gy_mean_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.mean())
X_train['Gz_mean_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.mean())

# FFT std dev
X_train['Ax_std_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.std())
X_train['Ay_std_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.std())
X_train['Az_std_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.std())
X_train['Gx_std_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.std())
X_train['Gy_std_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.std())
X_train['Gz_std_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.std())

# FFT avg absolute diff
X_train['Ax_aad_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Ay_aad_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Az_aad_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gx_aad_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gy_aad_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_train['Gz_aad_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))


# FFT min
X_train['Ax_min_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.min())
X_train['Ay_min_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.min())
X_train['Az_min_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.min())
X_train['Gx_min_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.min())
X_train['Gy_min_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.min())
X_train['Gz_min_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.min())


# FFT max
X_train['Ax_max_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.max())
X_train['Ay_max_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.max())
X_train['Az_max_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.max())
X_train['Gx_max_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.max())
X_train['Gy_max_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.max())
X_train['Gz_max_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.max())

# FFT max-min diff
X_train['Ax_maxmin_diff_fft'] = X_train['Ax_max_fft'] - X_train['Ax_min_fft']
X_train['Ay_maxmin_diff_fft'] = X_train['Ay_max_fft'] - X_train['Ay_min_fft']
X_train['Az_maxmin_diff_fft'] = X_train['Az_max_fft'] - X_train['Az_min_fft']
X_train['Gx_maxmin_diff_fft'] = X_train['Gx_max_fft'] - X_train['Gx_min_fft']
X_train['Gy_maxmin_diff_fft'] = X_train['Gy_max_fft'] - X_train['Gy_min_fft']
X_train['Gz_maxmin_diff_fft'] = X_train['Gz_max_fft'] - X_train['Gz_min_fft']

# FFT median
X_train['Ax_median_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.median(x))
X_train['Ay_median_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.median(x))
X_train['Az_median_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.median(x))
X_train['Gx_median_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.median(x))
X_train['Gy_median_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.median(x))
X_train['Gz_median_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.median(x))

# FFT median abs dev 
X_train['Ax_mad_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Ay_mad_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Az_mad_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gx_mad_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gy_mad_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_train['Gz_mad_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))

# FFT Interquartile range
X_train['Ax_IQR_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Ay_IQR_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Az_IQR_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gx_IQR_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gy_IQR_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_train['Gz_IQR_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))


# FFT values above mean
X_train['Ax_above_mean_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_train['Ay_above_mean_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_train['Az_above_mean_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_train['Gx_above_mean_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_train['Gy_above_mean_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_train['Gz_above_mean_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.sum(x > x.mean()))

# FFT number of peaks
X_train['Ax_peak_count_fft'] = pd.Series(Ax_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_train['Ay_peak_count_fft'] = pd.Series(Ay_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_train['Az_peak_count_fft'] = pd.Series(Az_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gx_peak_count_fft'] = pd.Series(Gx_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gy_peak_count_fft'] = pd.Series(Gy_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_train['Gz_peak_count_fft'] = pd.Series(Gz_list_fft).apply(lambda x: len(find_peaks(x)[0]))


# FFT skewness
X_train['Ax_skewness_fft'] = pd.Series(Ax_list_fft).apply(lambda x: stats.skew(x))
X_train['Ay_skewness_fft'] = pd.Series(Ay_list_fft).apply(lambda x: stats.skew(x))
X_train['Az_skewness_fft'] = pd.Series(Az_list_fft).apply(lambda x: stats.skew(x))
X_train['Gx_skewness_fft'] = pd.Series(Gx_list_fft).apply(lambda x: stats.skew(x))
X_train['Gy_skewness_fft'] = pd.Series(Gy_list_fft).apply(lambda x: stats.skew(x))
X_train['Gz_skewness_fft'] = pd.Series(Gz_list_fft).apply(lambda x: stats.skew(x))

# FFT kurtosis
X_train['Ax_kurtosis_fft'] = pd.Series(Ax_list_fft).apply(lambda x: stats.kurtosis(x))
X_train['Ay_kurtosis_fft'] = pd.Series(Ay_list_fft).apply(lambda x: stats.kurtosis(x))
X_train['Az_kurtosis_fft'] = pd.Series(Az_list_fft).apply(lambda x: stats.kurtosis(x))
X_train['Gx_kurtosis_fft'] = pd.Series(Gx_list_fft).apply(lambda x: stats.kurtosis(x))
X_train['Gy_kurtosis_fft'] = pd.Series(Gy_list_fft).apply(lambda x: stats.kurtosis(x))
X_train['Gz_kurtosis_fft'] = pd.Series(Gz_list_fft).apply(lambda x: stats.kurtosis(x))


# FFT energy
X_train['Ax_energy_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.sum(x**2)/50)
X_train['Ay_energy_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.sum(x**2)/50)
X_train['Az_energy_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.sum(x**2/50))
X_train['Gx_energy_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.sum(x**2)/50)
X_train['Gy_energy_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.sum(x**2)/50)
X_train['Gz_energy_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.sum(x**2/50))

# FFT avg resultant
X_train['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(Ax_list_fft)**2 + pd.Series(Ay_list_fft)**2 + pd.Series(Az_list_fft)**2 + pd.Series(Gx_list_fft)**2 + pd.Series(Gy_list_fft)**2 + pd.Series(Gz_list_fft)**2)**0.5)]

# FFT Signal magnitude area
#X_train['sma_fft'] = pd.Series(x_list_fft).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft).apply(lambda x: np.sum(abs(x)/50)) \
                     #+ pd.Series(z_list_fft).apply(lambda x: np.sum(abs(x)/50))

Ax_list = []
Ay_list = []
Az_list = []
Gx_list = []
Gy_list = []
Gz_list = []
test_labels = []

window_size = 100
step_size = 50

# creating overlaping windows of size window-size 100
for i in range(0, df_test.shape[0] - window_size, step_size):
    Ax = df_test['ABack_x'].values[i: i + 100]
    Ay = df_test['ABack_y'].values[i: i + 100]
    Az = df_test['ABack_z'].values[i: i + 100]
    Gx = df_test['GNeck_x'].values[i: i + 100]
    Gy = df_test['GNeck_y'].values[i: i + 100]
    Gz = df_test['GNeck_z'].values[i: i + 100]
    label = stats.mode(df_test['Behavior_1'][i: i + 100])[0][0]

    Ax_list.append(Ax)
    Ay_list.append(Ay)
    Az_list.append(Az)
    Gx_list.append(Gx)
    Gy_list.append(Gy)
    Gz_list.append(Gz)

    test_labels.append(label)

# Statistical Features on raw x, y and z in time domain
X_test = pd.DataFrame()

# mean
X_test['Ax_mean'] = pd.Series(Ax_list).apply(lambda x: x.mean())
X_test['Ay_mean'] = pd.Series(Ay_list).apply(lambda x: x.mean())
X_test['Az_mean'] = pd.Series(Az_list).apply(lambda x: x.mean())
X_test['Gx_mean'] = pd.Series(Gx_list).apply(lambda x: x.mean())
X_test['Gy_mean'] = pd.Series(Gy_list).apply(lambda x: x.mean())
X_test['Gz_mean'] = pd.Series(Gz_list).apply(lambda x: x.mean())

# std dev
X_test['Ax_std'] = pd.Series(Ax_list).apply(lambda x: x.std())
X_test['Ay_std'] = pd.Series(Ay_list).apply(lambda x: x.std())
X_test['Az_std'] = pd.Series(Az_list).apply(lambda x: x.std())
X_test['Gx_std'] = pd.Series(Gx_list).apply(lambda x: x.std())
X_test['Gy_std'] = pd.Series(Gy_list).apply(lambda x: x.std())
X_test['Gz_std'] = pd.Series(Gz_list).apply(lambda x: x.std())
# avg absolute diff
X_test['Ax_aad'] = pd.Series(Ax_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Ay_aad'] = pd.Series(Ay_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Az_aad'] = pd.Series(Az_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gx_aad'] = pd.Series(Gx_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gy_aad'] = pd.Series(Gy_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gz_aad'] = pd.Series(Gz_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))

# min
X_test['Ax_min'] = pd.Series(Ax_list).apply(lambda x: x.min())
X_test['Ay_min'] = pd.Series(Ay_list).apply(lambda x: x.min())
X_test['Az_min'] = pd.Series(Az_list).apply(lambda x: x.min())
X_test['Gx_min'] = pd.Series(Gx_list).apply(lambda x: x.min())
X_test['Gy_min'] = pd.Series(Gy_list).apply(lambda x: x.min())
X_test['Gz_min'] = pd.Series(Gz_list).apply(lambda x: x.min())

# max
X_test['Ax_max'] = pd.Series(Ax_list).apply(lambda x: x.max())
X_test['Ay_max'] = pd.Series(Ay_list).apply(lambda x: x.max())
X_test['Az_max'] = pd.Series(Az_list).apply(lambda x: x.max())
X_test['Gx_max'] = pd.Series(Gx_list).apply(lambda x: x.max())
X_test['Gy_max'] = pd.Series(Gy_list).apply(lambda x: x.max())
X_test['Gz_max'] = pd.Series(Gz_list).apply(lambda x: x.max())

# max-min diff
X_test['Ax_maxmin_diff'] = X_test['Ax_max'] - X_test['Ax_min']
X_test['Ay_maxmin_diff'] = X_test['Ay_max'] - X_test['Ay_min']
X_test['Az_maxmin_diff'] = X_test['Az_max'] - X_test['Az_min']
X_test['Gx_maxmin_diff'] = X_test['Gx_max'] - X_test['Gx_min']
X_test['Gy_maxmin_diff'] = X_test['Gy_max'] - X_test['Gy_min']
X_test['Gz_maxmin_diff'] = X_test['Gz_max'] - X_test['Gz_min']

# median
X_test['Ax_median'] = pd.Series(Ax_list).apply(lambda x: np.median(x))
X_test['Ay_median'] = pd.Series(Ay_list).apply(lambda x: np.median(x))
X_test['Az_median'] = pd.Series(Az_list).apply(lambda x: np.median(x))
X_test['Gx_median'] = pd.Series(Gx_list).apply(lambda x: np.median(x))
X_test['Gy_median'] = pd.Series(Gy_list).apply(lambda x: np.median(x))
X_test['Gz_median'] = pd.Series(Gz_list).apply(lambda x: np.median(x))

# median abs dev 
X_test['Ax_mad'] = pd.Series(Ax_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Ay_mad'] = pd.Series(Ay_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Az_mad'] = pd.Series(Az_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gx_mad'] = pd.Series(Gx_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gy_mad'] = pd.Series(Gy_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gz_mad'] = pd.Series(Gz_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))

# interquartile range
X_test['Ax_IQR'] = pd.Series(Ax_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Ay_IQR'] = pd.Series(Ay_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Az_IQR'] = pd.Series(Az_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gx_IQR'] = pd.Series(Gx_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gy_IQR'] = pd.Series(Gy_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gz_IQR'] = pd.Series(Gz_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))

# negtive count
X_test['Ax_neg_count'] = pd.Series(Ax_list).apply(lambda x: np.sum(x < 0))
X_test['Ay_neg_count'] = pd.Series(Ay_list).apply(lambda x: np.sum(x < 0))
X_test['Az_neg_count'] = pd.Series(Az_list).apply(lambda x: np.sum(x < 0))
X_test['Gx_neg_count'] = pd.Series(Gx_list).apply(lambda x: np.sum(x < 0))
X_test['Gy_neg_count'] = pd.Series(Gy_list).apply(lambda x: np.sum(x < 0))
X_test['Gz_neg_count'] = pd.Series(Gz_list).apply(lambda x: np.sum(x < 0))

# positive count
X_test['Ax_pos_count'] = pd.Series(Ax_list).apply(lambda x: np.sum(x > 0))
X_test['Ay_pos_count'] = pd.Series(Ay_list).apply(lambda x: np.sum(x > 0))
X_test['Az_pos_count'] = pd.Series(Az_list).apply(lambda x: np.sum(x > 0))
X_test['Gx_pos_count'] = pd.Series(Gx_list).apply(lambda x: np.sum(x > 0))
X_test['Gy_pos_count'] = pd.Series(Gy_list).apply(lambda x: np.sum(x > 0))
X_test['Gz_pos_count'] = pd.Series(Gz_list).apply(lambda x: np.sum(x > 0))

# values above mean
X_test['Ax_above_mean'] = pd.Series(Ax_list).apply(lambda x: np.sum(x > x.mean()))
X_test['Ay_above_mean'] = pd.Series(Ay_list).apply(lambda x: np.sum(x > x.mean()))
X_test['Az_above_mean'] = pd.Series(Az_list).apply(lambda x: np.sum(x > x.mean()))
X_test['Gx_above_mean'] = pd.Series(Gx_list).apply(lambda x: np.sum(x > x.mean()))
X_test['Gy_above_mean'] = pd.Series(Gy_list).apply(lambda x: np.sum(x > x.mean()))
X_test['Gz_above_mean'] = pd.Series(Gz_list).apply(lambda x: np.sum(x > x.mean()))

# number of peaks
X_test['Ax_peak_count'] = pd.Series(Ax_list).apply(lambda x: len(find_peaks(x)[0]))
X_test['Ay_peak_count'] = pd.Series(Ay_list).apply(lambda x: len(find_peaks(x)[0]))
X_test['Az_peak_count'] = pd.Series(Az_list).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gx_peak_count'] = pd.Series(Gx_list).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gy_peak_count'] = pd.Series(Gy_list).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gz_peak_count'] = pd.Series(Gz_list).apply(lambda x: len(find_peaks(x)[0]))

# skewness
X_test['Ax_skewness'] = pd.Series(Ax_list).apply(lambda x: stats.skew(x))
X_test['Ay_skewness'] = pd.Series(Ay_list).apply(lambda x: stats.skew(x))
X_test['Az_skewness'] = pd.Series(Az_list).apply(lambda x: stats.skew(x))
X_test['Gx_skewness'] = pd.Series(Gx_list).apply(lambda x: stats.skew(x))
X_test['Gy_skewness'] = pd.Series(Gy_list).apply(lambda x: stats.skew(x))
X_test['Gz_skewness'] = pd.Series(Gz_list).apply(lambda x: stats.skew(x))

# kurtosis
X_test['Ax_kurtosis'] = pd.Series(Ax_list).apply(lambda x: stats.kurtosis(x))
X_test['Ay_kurtosis'] = pd.Series(Ay_list).apply(lambda x: stats.kurtosis(x))
X_test['Az_kurtosis'] = pd.Series(Az_list).apply(lambda x: stats.kurtosis(x))
X_test['Gx_kurtosis'] = pd.Series(Gx_list).apply(lambda x: stats.kurtosis(x))
X_test['Gy_kurtosis'] = pd.Series(Gy_list).apply(lambda x: stats.kurtosis(x))
X_test['Gz_kurtosis'] = pd.Series(Gz_list).apply(lambda x: stats.kurtosis(x))

# energy
X_test['Ax_energy'] = pd.Series(Ax_list).apply(lambda x: np.sum(x**2)/100)
X_test['Ay_energy'] = pd.Series(Ay_list).apply(lambda x: np.sum(x**2)/100)
X_test['Az_energy'] = pd.Series(Az_list).apply(lambda x: np.sum(x**2/100))
X_test['Gx_energy'] = pd.Series(Gx_list).apply(lambda x: np.sum(x**2)/100)
X_test['Gy_energy'] = pd.Series(Gy_list).apply(lambda x: np.sum(x**2)/100)
X_test['Gz_energy'] = pd.Series(Gz_list).apply(lambda x: np.sum(x**2/100))


# avg resultant
X_test['avg_result_accl'] = [i.mean() for i in ((pd.Series(Ax_list)**2 + pd.Series(Ay_list)**2 + pd.Series(Az_list)**2 + pd.Series(Gx_list)**2 + pd.Series(Gy_list)**2 + pd.Series(Gz_list)**2)**0.5)]

# signal magnitude area
#X_train['sma'] =    pd.Series(Ax_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(Ay_list).apply(lambda x: np.sum(abs(x)/100)) 
                  #+ pd.Series(Az_list).apply(lambda x: np.sum(abs(x)/100) +  pd.Series(Gx_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(Gy_list).apply(lambda x: np.sum(abs(x)/100)) 
                  #+ pd.Series(Gz_list).apply(lambda x: np.sum(abs(x)/100))

## converting the signals from time domain to frequency domain using FFT
Ax_list_fft = pd.Series(Ax_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Ay_list_fft = pd.Series(Ay_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Az_list_fft = pd.Series(Az_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gx_list_fft = pd.Series(Gx_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gy_list_fft = pd.Series(Gy_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])
Gz_list_fft = pd.Series(Gz_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])


# Statistical Features on raw x, y and z in frequency domain
# FFT mean
X_test['Ax_mean_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.mean())
X_test['Ay_mean_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.mean())
X_test['Az_mean_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.mean())
X_test['Gx_mean_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.mean())
X_test['Gy_mean_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.mean())
X_test['Gz_mean_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.mean())

# FFT std dev
X_test['Ax_std_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.std())
X_test['Ay_std_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.std())
X_test['Az_std_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.std())
X_test['Gx_std_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.std())
X_test['Gy_std_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.std())
X_test['Gz_std_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.std())

# FFT avg absolute diff
X_test['Ax_aad_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Ay_aad_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Az_aad_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gx_aad_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gy_aad_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))
X_test['Gz_aad_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))


# FFT min
X_test['Ax_min_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.min())
X_test['Ay_min_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.min())
X_test['Az_min_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.min())
X_test['Gx_min_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.min())
X_test['Gy_min_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.min())
X_test['Gz_min_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.min())


# FFT max
X_test['Ax_max_fft'] = pd.Series(Ax_list_fft).apply(lambda x: x.max())
X_test['Ay_max_fft'] = pd.Series(Ay_list_fft).apply(lambda x: x.max())
X_test['Az_max_fft'] = pd.Series(Az_list_fft).apply(lambda x: x.max())
X_test['Gx_max_fft'] = pd.Series(Gx_list_fft).apply(lambda x: x.max())
X_test['Gy_max_fft'] = pd.Series(Gy_list_fft).apply(lambda x: x.max())
X_test['Gz_max_fft'] = pd.Series(Gz_list_fft).apply(lambda x: x.max())

# FFT max-min diff
X_test['Ax_maxmin_diff_fft'] = X_test['Ax_max_fft'] - X_test['Ax_min_fft']
X_test['Ay_maxmin_diff_fft'] = X_test['Ay_max_fft'] - X_test['Ay_min_fft']
X_test['Az_maxmin_diff_fft'] = X_test['Az_max_fft'] - X_test['Az_min_fft']
X_test['Gx_maxmin_diff_fft'] = X_test['Gx_max_fft'] - X_test['Gx_min_fft']
X_test['Gy_maxmin_diff_fft'] = X_test['Gy_max_fft'] - X_test['Gy_min_fft']
X_test['Gz_maxmin_diff_fft'] = X_test['Gz_max_fft'] - X_test['Gz_min_fft']

# FFT median
X_test['Ax_median_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.median(x))
X_test['Ay_median_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.median(x))
X_test['Az_median_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.median(x))
X_test['Gx_median_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.median(x))
X_test['Gy_median_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.median(x))
X_test['Gz_median_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.median(x))

# FFT median abs dev 
X_test['Ax_mad_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Ay_mad_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Az_mad_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gx_mad_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gy_mad_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))
X_test['Gz_mad_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.median(np.absolute(x - np.median(x))))

# FFT Interquartile range
X_test['Ax_IQR_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Ay_IQR_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Az_IQR_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gx_IQR_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gy_IQR_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))
X_test['Gz_IQR_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))


# FFT values above mean
X_test['Ax_above_mean_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_test['Ay_above_mean_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_test['Az_above_mean_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_test['Gx_above_mean_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_test['Gy_above_mean_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.sum(x > x.mean()))
X_test['Gz_above_mean_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.sum(x > x.mean()))

# FFT number of peaks
X_test['Ax_peak_count_fft'] = pd.Series(Ax_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_test['Ay_peak_count_fft'] = pd.Series(Ay_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_test['Az_peak_count_fft'] = pd.Series(Az_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gx_peak_count_fft'] = pd.Series(Gx_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gy_peak_count_fft'] = pd.Series(Gy_list_fft).apply(lambda x: len(find_peaks(x)[0]))
X_test['Gz_peak_count_fft'] = pd.Series(Gz_list_fft).apply(lambda x: len(find_peaks(x)[0]))


# FFT skewness
X_test['Ax_skewness_fft'] = pd.Series(Ax_list_fft).apply(lambda x: stats.skew(x))
X_test['Ay_skewness_fft'] = pd.Series(Ay_list_fft).apply(lambda x: stats.skew(x))
X_test['Az_skewness_fft'] = pd.Series(Az_list_fft).apply(lambda x: stats.skew(x))
X_test['Gx_skewness_fft'] = pd.Series(Gx_list_fft).apply(lambda x: stats.skew(x))
X_test['Gy_skewness_fft'] = pd.Series(Gy_list_fft).apply(lambda x: stats.skew(x))
X_test['Gz_skewness_fft'] = pd.Series(Gz_list_fft).apply(lambda x: stats.skew(x))

# FFT kurtosis
X_test['Ax_kurtosis_fft'] = pd.Series(Ax_list_fft).apply(lambda x: stats.kurtosis(x))
X_test['Ay_kurtosis_fft'] = pd.Series(Ay_list_fft).apply(lambda x: stats.kurtosis(x))
X_test['Az_kurtosis_fft'] = pd.Series(Az_list_fft).apply(lambda x: stats.kurtosis(x))
X_test['Gx_kurtosis_fft'] = pd.Series(Gx_list_fft).apply(lambda x: stats.kurtosis(x))
X_test['Gy_kurtosis_fft'] = pd.Series(Gy_list_fft).apply(lambda x: stats.kurtosis(x))
X_test['Gz_kurtosis_fft'] = pd.Series(Gz_list_fft).apply(lambda x: stats.kurtosis(x))


# FFT energy
X_test['Ax_energy_fft'] = pd.Series(Ax_list_fft).apply(lambda x: np.sum(x**2)/50)
X_test['Ay_energy_fft'] = pd.Series(Ay_list_fft).apply(lambda x: np.sum(x**2)/50)
X_test['Az_energy_fft'] = pd.Series(Az_list_fft).apply(lambda x: np.sum(x**2/50))
X_test['Gx_energy_fft'] = pd.Series(Gx_list_fft).apply(lambda x: np.sum(x**2)/50)
X_test['Gy_energy_fft'] = pd.Series(Gy_list_fft).apply(lambda x: np.sum(x**2)/50)
X_test['Gz_energy_fft'] = pd.Series(Gz_list_fft).apply(lambda x: np.sum(x**2/50))

# FFT avg resultant
X_test['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(Ax_list_fft)**2 + pd.Series(Ay_list_fft)**2 + pd.Series(Az_list_fft)**2 + pd.Series(Gx_list_fft)**2 + pd.Series(Gy_list_fft)**2 + pd.Series(Gz_list_fft)**2)**0.5)]

# FFT Signal magnitude area
#X_train['sma_fft'] = pd.Series(x_list_fft).apply(lambda x: np.sum(abs(x)/50)) + pd.Series(y_list_fft).apply(lambda x: np.sum(abs(x)/50)) \
                     #+ pd.Series(z_list_fft).apply(lambda x: np.sum(abs(x)/50))

y_train = np.array(train_labels)
y_test = np.array(test_labels)

X_test2=X_test.fillna(X_test.mean())

msno.matrix(X_test.sample(250))

# standardization
scaler = StandardScaler()
scaler.fit(X_train)
X_train_data_lr = scaler.transform(X_train)
X_test_data_lr = scaler.transform(X_test)
# logistic regression model
lr = LogisticRegression(random_state = 21)
lr.fit(X_train_data_lr, y_train)
y_pred = lr.predict(X_test_data_lr)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\n -------------Classification Report-------------\n")
print(classification_report(y_test, y_pred))

range_k = range(1,10)
scores = {}
scores_list = []

classifier = KNeighborsClassifier(n_neighbors=10)
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
scores = metrics.accuracy_score(y_test,y_pred)
scores_list.append(metrics.accuracy_score(y_test,y_pred))
result = metrics.confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(result)
result1 = metrics.classification_report(y_test, y_pred)
print("Classification Report:",)
print (result1)

